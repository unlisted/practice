binary search
works on sorted list
divide in half each iteration
worst case O(log(n)) complexity

bubble sort
iterate through list swapping values with next if next is less than current
poor performance for large n
worst case O(n^2) - worst occurs when list is reversed
best case O(n) - list is already sorted
space O(1) ??
in place
stable

merge sort
split data set in half recursively until single elements exist, then merge sorting
worst casr O(nlog(n)) worst,average and best divides into halve (O(log(n)) linear time to merge (O(n))
space O(n)
stable

